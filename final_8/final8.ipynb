{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Урок 8. GAN\n",
        "###  - Обучите нейронную сеть любой архитектуры, которой не было на курсе, либо нейронную сеть разобранной архитектуры, <br>но на том датасете, которого не было на уроках. <br> - Сделайте анализ того, что вам помогло<br> в улучшения работы нейронной сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aG4zSpJ4fdd6"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pyV3BrPfhLU",
        "outputId": "4375a8d0-3d5e-491d-fef4-77ed00554214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/JurgenPalsma/swarmex/archive/refs/heads/master.zip to ./swarmex-master.zip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20684800it [00:13, 1512069.36it/s]\n"
          ]
        }
      ],
      "source": [
        "od.download(\"https://github.com/JurgenPalsma/swarmex/archive/refs/heads/master.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRY61Pe4fpTL",
        "outputId": "873839dd-cec5-4961-a45d-87c63dc25404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /neyroseti/swarmex-master.zip, /neyroseti/swarmex-master.zip.zip or /neyroseti/swarmex-master.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/neyroseti/swarmex-master.zip\" -d \"/neyroseti/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ol544qCgZzP",
        "outputId": "39eaaabd-ffb9-49a2-8d37-13d77d0fd1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/semen/Ucheba/DZ/II/neyroseti/swarmex-master\n"
          ]
        }
      ],
      "source": [
        "%cd swarmex-master/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AJ8PI6Hgr4X",
        "outputId": "065f458e-3466-4b7f-93f3-a41f515e35b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: строка 1: python: команда не найдена\n"
          ]
        }
      ],
      "source": [
        "!python main.py -c ./config/demo.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6NLpCvLjUrX"
      },
      "source": [
        "Решил использовать нейросеть с использованием _partical swarm optimization_.\n",
        "Метод роя частиц (МРЧ) — метод численной оптимизации, для использования которого не требуется знать точного градиента оптимизируемой функции.\n",
        "МРЧ был доказан Кеннеди, Эберхартом и Ши[1][2] и изначально предназначался для имитации социального поведения. Алгоритм был упрощён, и было замечено, что он пригоден для выполнения оптимизации. Книга Кеннеди и Эберхарта[3] описывает многие философские аспекты МРЧ и так называемого роевого интеллекта. Обширное исследование приложений МРЧ сделано Поли[4][5]. МРЧ оптимизирует функцию, поддерживая популяцию возможных решений, называемых частицами, и перемещая эти частицы в пространстве решений согласно простой формуле. Перемещения подчиняются принципу наилучшего найденного в этом пространстве положения, которое постоянно изменяется при нахождении частицами более выгодных положений.  \n",
        "Для применения модели выбрал работу JurgenPalsma на [github](https://github.com/JurgenPalsma/swarmex).  \n",
        "Полноценный тестовый запус осуществить не удалось, поэтому обратился к другому источнику."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pyswarms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rdybsInyipd",
        "outputId": "c9980f88-1f84-4209-bc7e-fc94c7515d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/semen/Ucheba/DZ/II/neyroseti\n",
            "/home/semen/Ucheba/DZ/II/neyroseti\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vts4nmv_w3Gf"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "\n",
        "# Import PySwarms\n",
        "import pyswarms as ps\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K1OwSXY1xMep"
      },
      "outputs": [],
      "source": [
        "# список признаков, по которым будем учить\n",
        "channelIndexes = [0, 1, 2, 3]\n",
        "#channelIndexes = [0,1,2]\n",
        "\n",
        "# длина истории для работы\n",
        "xLen = 8\n",
        "# отступ тестов от тренировок\n",
        "bias = 4\n",
        "\n",
        "# шаг по данным для построения обучающих примеров\n",
        "step = 1\n",
        "\n",
        "# горизонт предсказания\n",
        "future = 1\n",
        "\n",
        "\n",
        "# параметры модели для обучения\n",
        "batch_size = 8\n",
        "epochs = 5\n",
        "\n",
        "train_split_percents = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ctqUJzSLx_KJ"
      },
      "outputs": [],
      "source": [
        "def data_get(path_to_csv, start_date, batch_size):\n",
        "  df = pd.read_csv(path_to_csv, usecols=['<DATE>','<HIGH>','<LOW>'],\n",
        "                   index_col=['<DATE>'], parse_dates=['<DATE>'],) \n",
        "  df = df[df.index >= pd.to_datetime(start_date)]\n",
        "  df[\"HLAvg\"] = df['<HIGH>'].add(df['<LOW>']).div(2)\n",
        "  del df['<HIGH>']\n",
        "  del df['<LOW>']\n",
        "\n",
        "  # Простое скользящее среднее\n",
        "  df['MA'] = df['HLAvg'].rolling(window=14).mean()\n",
        "  # Логарифмический возврат\n",
        "  df['Returns'] = np.log(df['MA']/df['MA'].shift(1))\n",
        "  \n",
        "  df.dropna(how='any', inplace=True)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHrqi12J-Che"
      },
      "source": [
        "#### Попытка применения нейросети на данных с котировками CHFUSD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWJ2XQqUyCZT",
        "outputId": "95d6cc4f-d867-49f7-f660-c7791e65e943"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4066, 3), (1369, 3), (1369, 3))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = data_get('./CHFUSD_210101_220118_1H.csv', '01.01.2021', batch_size)\n",
        "# Простое скользящее среднее\"\n",
        "df['MA'] = df['HLAvg'].rolling(window=xLen).mean()\n",
        "# Log Returns\n",
        "df['Returns'] = np.log(df['MA']/df['MA'].shift(1))\n",
        "df.dropna(how='any', inplace=True)\n",
        "df = df[df.shape[0] % batch_size:]\n",
        "validation_size = round(df.shape[0]*0.2)\n",
        "test_size = round(df.shape[0]*0.2)\n",
        "df_train = df[:- validation_size - test_size]\n",
        "df_validation = df[- validation_size - test_size - xLen:- test_size]\n",
        "df_test = df[- test_size - xLen:]\n",
        "df_train.shape, df_validation.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sPzhUvwAzR7K"
      },
      "outputs": [],
      "source": [
        "def get_train(values, window_size):\n",
        "    X, y = [], []\n",
        "    len_values = len(values)\n",
        "    for i in range(window_size, len_values):\n",
        "        X.append(values[i-window_size:i])\n",
        "        y.append(values[i])\n",
        "    X, y = np.asarray(X), np.asarray(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
        "    y = np.reshape(y, y.shape[0])\n",
        "    return X, y\n",
        "\n",
        "def get_val(values, window_size):\n",
        "    X = []\n",
        "    len_values = len(values)\n",
        "    for i in range(window_size, len_values):\n",
        "        X.append(values[i-window_size:i])\n",
        "    X = np.asarray(X)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    y = values[-X.shape[0]:]\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GypjQHEwzwJ2",
        "outputId": "97d0de63-b195-4bbe-f098-e68315372117"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6762, 14), (6762,))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = get_train(df[['Returns']].values, xLen)\n",
        "y[y<-0.000001] = -1\n",
        "y[y>0.000001] = 1\n",
        "y = np.where((y>-0.000001)&(y<0.000001), 0, y)\n",
        "y = y.astype(int)\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QrS_t9lWz4zO"
      },
      "outputs": [],
      "source": [
        "# Прямое распространение\n",
        "def forward_prop(params):\n",
        "    \"\"\"Функция прямого распространения в качестве функции цели \n",
        "\n",
        "    Эта функция вычисляет прямое распространения в нейронной сети, а также расчитывает потерю.\n",
        "    Она получает набор параметров, которые должны быть\n",
        "    развернуты в соответствующие веса и смещения.\n",
        "\n",
        "    Входные данные\n",
        "    ------\n",
        "    Параметры: np.ndarray\n",
        "        Размерности должны включать развернутую версию\n",
        "        весов и смещений.\n",
        "\n",
        "    Возвращает\n",
        "    -------\n",
        "    float\n",
        "        Вычисленная потеря отрицательной логарифмической вероятности при заданных параметрах.\n",
        "    \"\"\"\n",
        "    # Архитектура нейронной сети\n",
        "    n_inputs = 14\n",
        "    n_hidden = 370\n",
        "    n_classes = 3\n",
        "\n",
        "    # Откат весов и смещений\n",
        "    W1 = params[0:5180].reshape((n_inputs,n_hidden))\n",
        "    b1 = params[5180:5550].reshape((n_hidden,))\n",
        "    W2 = params[5550:6660].reshape((n_hidden,n_classes))\n",
        "    b2 = params[6660:6663].reshape((n_classes,))\n",
        "\n",
        "    # Выполнение прямого распространения\n",
        "    z1 = X.dot(W1) + b1  # Предварительная активация на 1 слое\n",
        "    a1 = np.tanh(z1)     # Активация на 1 слое\n",
        "    z2 = a1.dot(W2) + b2 # предварительная активация на 2 слое\n",
        "    logits = z2          # Логиты для 2 слоев \n",
        "\n",
        "    # Вычисление логитов softmax\n",
        "    exp_scores = np.exp(logits)\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    # Вычисление отрицательной логарифмической вероятности\n",
        "    N = 6762 # Количество выборок\n",
        "    corect_logprobs = -np.log(probs[range(N)])\n",
        "    loss = np.sum(corect_logprobs) / N\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Для выполнения прямого распространения в рою можно использовать более высокоуровневый метод, называемый \"глобальным прямым распространением\". В этом методе каждая частица в рое вычисляет свою собственную потерю индивидуально, а затем потери от всех частиц собираются для получения общей потери для всего роя.\n",
        "\n",
        "##### Вот шаги, включенные в метод глобального прямого распространения:\n",
        "\n",
        "##### 1. Каждая частица в рое выполняет прямое распространение независимо, используя свой собственный набор весов и смещений. Это включает передачу входных данных через модель нейронной сети и вычисление предсказанных выходных значений.\n",
        "\n",
        "##### 2. После прямого распространения каждая частица вычисляет свою собственную потерю, сравнивая свои предсказанные выходные значения с фактическими метками с помощью функции потерь, такой как среднеквадратичная ошибка или перекрестная энтропия.\n",
        "\n",
        "##### 3. Затем потери от всех частиц собираются и агрегируются для получения общей потери для всего роя. Это можно сделать, взяв среднее значение индивидуальных потерь или с использованием взвешенного среднего на основе приспособленности или производительности частицы.\n",
        "\n",
        "##### 4. Общая потеря затем используется для обновления глобального лучшего положения и лучшей приспособленности роя, если необходимо, на основе функции приспособленности, которая оценивает производительность каждой частицы.\n",
        "\n",
        "##### 5. Наконец, обновленное глобальное лучшее положение используется для обновления весов и смещений каждой частицы в рое, что позволяет им учиться на основе совокупных знаний всего роя.\n",
        "\n",
        "##### Использование глобального прямого распространения позволяет рою эффективно исследовать пространство поиска и находить лучшие решения коллективно. Это позволяет эффективно обмениваться информацией и учиться на опыте друг друга, что приводит к улучшению производительности и скорости сходимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IpYtqIjlz_TP"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    \n",
        "    \n",
        "    \"\"\"Более высокоуровневый метод для выполнения прямого распространения во всем рое.\n",
        "\n",
        "    Входные данные\n",
        "    ------\n",
        "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
        "          Рой, который будет выполнять поиск\n",
        "\n",
        "    Возвращает \n",
        "    -------\n",
        "    numpy.ndarray of shape (n_particles, )\n",
        "        Вычисленные потери для каждой частицы\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKpkRgX-0Cxf",
        "outputId": "f6fe22a5-fd7d-411e-ac26-4efca84e81cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-17 19:35:12,562 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "pyswarms.single.global_best: 100%|██████████|100/100, best_cost=3.3\n",
            "2023-07-17 20:08:11,034 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 3.295893309325902, best pos: [1.057356   1.43019339 0.82459699 ... 0.38761439 0.28801263 0.71547585]\n"
          ]
        }
      ],
      "source": [
        "# Инициализировать рой\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
        "\n",
        "# Вызов экземпляра PSO\n",
        "dimensions = y.shape[0]\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
        "\n",
        "# Выполняем оптимизацию\n",
        "cost, pos = optimizer.optimize(f, iters=100, verbose=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pzNl37YPKET7"
      },
      "outputs": [],
      "source": [
        "def predict(X, pos):\n",
        "    \"\"\"\n",
        "    Используем обученные веса для выполнения предсказаний классов.\n",
        "\n",
        "    Входные данные\n",
        "    ------\n",
        "    X: numpy.ndarray\n",
        "        Входной набор данных Iris\n",
        "    pos: numpy.ndarray\n",
        "        Матрица позиций, найденная роем. Будет преобразована\n",
        "        в веса и смещения.\n",
        "    \"\"\"\n",
        "    # Архитектура нейронной сети\n",
        "    n_inputs = 14\n",
        "    n_hidden = 370\n",
        "    n_classes = 3\n",
        "\n",
        "    # Преобразовать обратно веса и смещения.\n",
        "    W1 = pos[0:5180].reshape((n_inputs,n_hidden))\n",
        "    b1 = pos[5180:5550].reshape((n_hidden,))\n",
        "    W2 = pos[5550:6660].reshape((n_hidden,n_classes))\n",
        "    b2 = pos[6660:6663].reshape((n_classes,))\n",
        "\n",
        "    # Выполнение прямого распространения\n",
        "    z1 = X.dot(W1) + b1  # Преактивация в слое 1\n",
        "    a1 = np.tanh(z1)     # Aктивация в слое 1\n",
        "    z2 = a1.dot(W2) + b2 # Преактивация в слое 2\n",
        "    logits = z2          # Логиты для слоя 2.\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXsfEiPXbC6X",
        "outputId": "8c258cef-afd6-4af3-f2a0-d9ab21c7c2e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.43966282165039927"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(predict(X, pos) == y).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB638ueJ-NNg"
      },
      "source": [
        "#### Попытка применения нейросети по [образцу](https://pyswarms.readthedocs.io/en/development/examples/custom_objective_function.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Fb5SHNMz0JMy"
      },
      "outputs": [],
      "source": [
        "# Загрузка набора данных iris.\n",
        "data = load_iris()\n",
        "\n",
        "# Сохраним признаки в переменную X и метки в переменную y.\n",
        "X = data.data\n",
        "y = data.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGx1s3Rr1ipV",
        "outputId": "a375890f-192c-4d08-ea9a-2a7da50d67dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzRPMye31qul",
        "outputId": "bc8e2cb5-79ce-484b-df3e-41b307be7efa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4,), array([], shape=(0, 4), dtype=float64))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0].shape, X[160:163]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KDJJeq154rc8"
      },
      "outputs": [],
      "source": [
        "# Прямое распространение\n",
        "def forward_prop(params):\n",
        "    \"\"\"Прямое распространение как целевая функция\n",
        "\n",
        "    то вычисляет прямое распространение нейронной сети, а также потерю. \n",
        "    Он получает набор параметров, которые должны быть преобразованы обратно \n",
        "    в соответствующие веса и смещения.\n",
        "\n",
        "    Входные данные \n",
        "    ------\n",
        "    params: np.ndarray\n",
        "        Размерности должны включать развернутую версию весов и смещений.\n",
        "    Возвращает \n",
        "    -------\n",
        "    float\n",
        "        Вычисленная потеря отрицательного логарифма правдоподобия на основе параметров\"\n",
        "    \"\"\"\n",
        "    # Архитектура нейронной сети\n",
        "    n_inputs = 4\n",
        "    n_hidden = 20\n",
        "    n_classes = 3\n",
        "\n",
        "    # Преобразовать обратно веса и смещения\n",
        "    W1 = params[0:80].reshape((n_inputs,n_hidden))\n",
        "    b1 = params[80:100].reshape((n_hidden,))\n",
        "    W2 = params[100:160].reshape((n_hidden,n_classes))\n",
        "    b2 = params[160:163].reshape((n_classes,))\n",
        "\n",
        "    # Выполнение прямого распространения\n",
        "    z1 = X.dot(W1) + b1  # Преактивация в слое 1\n",
        "    a1 = np.tanh(z1)     # Активация в слое 1\n",
        "    z2 = a1.dot(W2) + b2 # Преактивация в слое 2\n",
        "    logits = z2          # Активация в слое 2\n",
        "\n",
        "    # Вычисление софтмакс для логитов\n",
        "    exp_scores = np.exp(logits)\n",
        "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "    # Вычисление отрицательной логарифмической функциии правдоподобия\"\n",
        "    N = 150 # Количество выборок\n",
        "    corect_logprobs = -np.log(probs[range(N), y])\n",
        "    loss = np.sum(corect_logprobs) / N\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6oJCudQw54fH"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    \"\"\"Более высокоуровневый метод для выполнения прямого распространения во всем рое.\n",
        "    Входные данные\n",
        "    ------\n",
        "    x: numpy.ndarray формы (n_particles, dimensions)\n",
        "        Рой, которая будет выполнять поиск.\n",
        "\n",
        "    Возвращает\n",
        "    -------\n",
        "    numpy.ndarray формы (n_particles, )\n",
        "        Рассчитанная ошибка для каждой частицы.\"\n",
        "    \"\"\"\n",
        "    n_particles = x.shape[0]\n",
        "    j = [forward_prop(x[i]) for i in range(n_particles)]\n",
        "    return np.array(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp9rEb1_57TB",
        "outputId": "83908c3a-3656-4553-cf7b-10040467357a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-17 20:08:50,143 - pyswarms.single.global_best - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|1000/1000, best_cost=0.0167\n",
            "2023-07-17 20:09:16,926 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.016707792584817856, best pos: [ 2.12250207e-02 -2.44845659e+00  5.45244510e-02  3.43632934e-01\n",
            "  1.46979696e+00 -1.33790078e+00 -2.55690565e-01 -5.38755875e-02\n",
            " -2.90750202e-01 -2.40284581e-01 -2.47165769e-01  1.56102898e+00\n",
            "  1.07994805e+00  6.86582629e-01  4.34812111e-01  5.50903660e-01\n",
            " -3.29546330e-02  5.61361610e-01 -2.15849666e+00  2.74973457e+00\n",
            " -4.00439231e-02  7.90912862e-01  1.06898901e+00  5.59940720e-03\n",
            "  4.40758309e-01 -4.40404646e-03 -2.16243600e+00  2.53089281e+00\n",
            " -4.94778459e-01 -3.02724413e+00 -1.04152155e-01 -9.97809207e-01\n",
            " -7.14625698e-01 -8.01319513e-01 -3.23297116e-02 -1.27151303e+00\n",
            "  8.63220269e-01 -6.63231686e-01 -6.97831685e-01 -3.39071868e-01\n",
            " -5.82367670e-01 -3.88147281e-01 -9.61959509e-01 -1.26433815e+00\n",
            "  2.75193769e+00 -7.17545719e-01  1.88838892e+00  5.01244861e-02\n",
            "  1.72902958e+00  5.57033592e-01 -1.40543991e+00  6.98315277e-01\n",
            "  1.22126496e+00 -2.08132729e-01  5.21082669e-01  6.72144127e-01\n",
            " -6.64267423e-01 -4.71845312e-01  6.24002582e-01  8.43003669e-01\n",
            "  1.33172296e-01  7.91457388e-02 -1.66234215e+00  4.69554491e-01\n",
            " -1.15646481e+01 -3.68390659e-01  1.46732670e+00  2.39833594e-01\n",
            "  8.90199299e-01 -3.62509687e-01  7.46483663e-01 -9.64151897e-01\n",
            "  9.33575317e-01 -6.79441026e-02 -1.93849439e+00  4.48675789e-01\n",
            " -5.45460847e-01  1.01517659e+00 -1.34721065e+00  3.79266972e-01\n",
            "  1.05351083e+00  3.90689812e-01  2.79799410e-01  3.17866211e+00\n",
            " -3.01780341e+00  4.29490032e-01 -1.11775791e+00 -1.28893624e+00\n",
            " -6.46501143e+00 -2.12348044e-01 -1.31145672e-01  2.16659309e+00\n",
            " -1.43706358e-01 -2.62238550e-01 -1.32097561e-01  3.39613173e-01\n",
            "  7.04435235e-01 -3.47769488e-02 -1.17083551e+00  1.34446325e+00\n",
            " -2.53644046e-01 -6.68498298e-01 -4.50667859e-01 -1.87837873e-01\n",
            " -8.07785291e-01  2.07049813e-01  1.60941106e+01 -9.45521058e+00\n",
            "  1.58160849e-01  7.02212393e-01 -9.53692283e-01 -8.55702916e-01\n",
            " -1.87829750e-01  1.61672355e+01 -6.24696166e-01  2.30109833e-01\n",
            "  7.26868913e-01 -1.22316796e-01 -3.00303022e-01  1.98837070e+00\n",
            " -1.10136334e+00  6.33255572e-01 -2.37819747e-02 -8.02250501e-01\n",
            " -1.49369460e+00 -5.39998440e-01  2.83339532e+01  1.71707365e-01\n",
            "  6.94127773e-01 -3.86044553e-01 -5.27051540e-01 -3.69147891e-01\n",
            "  2.62114541e-01  4.69177985e-02  7.41613366e-01  1.42528680e-01\n",
            "  2.95289515e+00  1.06335841e+00  2.47444720e+00  6.91672374e-01\n",
            " -1.49928195e+00  3.81941316e+01  2.01078975e-01 -1.48453651e-01\n",
            "  9.74948287e-01 -1.85713577e+00  1.49244775e+00 -4.34265446e-01\n",
            "  1.22872549e+00 -1.46474649e+00 -4.74884243e-01 -1.17539149e+00\n",
            "  1.04904251e+01  2.07552595e-01 -1.69836553e+00  4.07003649e-01\n",
            " -1.54064007e-02 -1.30922213e+00 -6.68709367e-01  1.31757471e-01\n",
            " -1.34923975e+00 -1.68581397e-01 -2.45483822e-01]\n"
          ]
        }
      ],
      "source": [
        "# Инициализировать роевой алгоритм.\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
        "\n",
        "# Вызов экземпляра метода PSO\n",
        "dimensions = (4 * 20) + (20 * 3) + 20 + 3\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimensions, options=options)\n",
        "\n",
        "# Производим оптимизацию\n",
        "cost, pos = optimizer.optimize(objective_func=f, iters=1000, verbose=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tWV_JcfI5-eQ"
      },
      "outputs": [],
      "source": [
        "def predict(X, pos):\n",
        "    \"\"\"\n",
        "    Используем обученные веса для выполнения предсказаний классов.\n",
        "\n",
        "    Входные данные\n",
        "    ------\n",
        "    X: numpy.ndarray\n",
        "        Входной набор данных Iris\n",
        "    pos: numpy.ndarray\n",
        "        Матрица позиций, найденных роем. Будет преобразована в веса\n",
        "        и смещения.\n",
        "    \"\"\"\n",
        "    # Архитектура нейронной сети\n",
        "    n_inputs = 4\n",
        "    n_hidden = 20\n",
        "    n_classes = 3\n",
        "\n",
        "    #Преобразовать обратно веса и смещения\n",
        "    W1 = pos[0:80].reshape((n_inputs,n_hidden))\n",
        "    b1 = pos[80:100].reshape((n_hidden,))\n",
        "    W2 = pos[100:160].reshape((n_hidden,n_classes))\n",
        "    b2 = pos[160:163].reshape((n_classes,))\n",
        "\n",
        "    # Выполнение прямого распространения\n",
        "    z1 = X.dot(W1) + b1  #  Преактивация в слое 1\n",
        "    a1 = np.tanh(z1)     #  Активация в слое 1\n",
        "    z2 = a1.dot(W2) + b2 #  Преактивация в слое 2\n",
        "    logits = z2          #  Активация в слое 2\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=1)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DAFOG3A90yQ",
        "outputId": "ec94888f-8ad9-4e0c-ded8-734c7e9e63cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9866666666666667"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(predict(X, pos) == y).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ushOTu7YKHNp"
      },
      "source": [
        "### Сделайте краткий обзор научной работы, посвящённой алгоритму нейронных сетей, \t не рассматриваемому ранее на курсе. Проведите анализ: чем отличается выбранная архитектура от других? В чём плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при её применении на практике?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptnhA7cbcg86"
      },
      "source": [
        "Particle swarm optimizer эффективный механизм, исходя из статей, [статья ](https://learn.microsoft.com/ru-ru/archive/msdn-magazine/2011/august/artificial-intelligence-particle-swarm-optimization) ,[статья ](https://www.researchgate.net/publication/363840097_A_Concise_Overview_of_Particle_Swarm_Optimization_Methods) Для дополнительного понимания были использованы некотые материалы<br>\n",
        "- Shi Y., Eberhart R.C. Parameter selection in particle swarm optimization, in: International conference\n",
        "on evolutionary programming,Springer, 1998 DOI:10.1007/BFb0040810, pp. 591–600.\n",
        "- Marandi A., Afshinmanesh F., Shahabadi M., Bahrami F. Boolean particle swarm optimization and\n",
        "its application to the design of a dual-band dual-polarized planar antenna, 2006 IEEE Interna-\n",
        "tional Conference on Evolutionary Computation, IEEE, 2006 DOI: 10.1109/CEC.2006.1688716,\n",
        "pp. 3212-3218\n",
        "- Hamada M., Hassan M. Artiﬁcial neural networks and particle swarm optimization algorithms for\n",
        "preference prediction in multicriteria recommender systems,Informatics, 5, Multidisciplinary Dig-\n",
        "ital Publishing Institute, 2018 DOI: 10.3390/informatics5020025. vol. 5, no. 2, pp. 25.\n",
        "- Манусов В. З., Матренин П. В., Насрулло Х. Применение алгоритмов роевого интеллекта\n",
        "в управлении генерирующим потребителем с возобновляемыми источниками энергии,Сист.\n",
        "анал. и обработ. данных,2019 DOI: 10.17212/1814-1196-2019-3-115-134. Т. 76, № 3, С. 115-13\n",
        "- Частикова В. А., Власов К. А., Картамышев Д. А. Обнаружение DDoS-атак на основе нейронных\n",
        "сетей с применением метода роя частиц в качестве алгоритма обучения, Фундаментальные\n",
        "исследования, 2014. Т. 4, № 8, С. 829-832.\n",
        "### Заключение \n",
        "В заключение можно сказать, что PSO продемонстрировал преимущество во многих областях применения по сравнению со многими другими алгоритмами оптимизации. Некоторые недостатки, выявленные в алгоритме, были уменьшены различными модификациями канонического ω-PSO. Данный метод оптимизации является универсальным, что еще больше подчеркивает его эффективность. Такая гибкость сделала PSO надежным оптимизатором в самых разных, но сложных сценариях оптимизации. Методы оптимизации обладают значительной способностью\n",
        "управлять задачами в сложных и обширных системах\n",
        "Но для того что бы разобраться в этой не простой теме нужна постоянная практика и изучение дополнителной литературы(банально не хватает знаний). Очень сложная и емкая тема. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Lesson_8.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
