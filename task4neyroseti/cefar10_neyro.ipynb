{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Урок 4. Сверточные нейронные сети\n",
        "- Попробуйте улучшить точность распознавания образов cifar 10 сверточной нейронной сетью, <br>рассмотренной на уроке. Приложите анализ с описанием того, что улучшает <br>работу нейронной сети, а что ухудшает\n",
        "- Опишите в анализе, какие изменения необходимо было бы внести в получившуюся нейронную сеть,<br> если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "mnist - Мы получаем точность около 87,5% при проверке набора после 20 эпох, в то время как с полностью подключенной нейронной сетью мы получаем 85% <br>\n",
        "cifar10 - По истечении 20 эпох точность нашей проверки не превысила 73%, в то время как точность  обучения продолжает расти до 92%.\n",
        "\n",
        "cifar10- этот набор данных более сложный, чем mnist\n",
        "сверточная нейронная сеть будет представлять собой набор измененных слоев <br>Conv2D и MaxPooling2D одинаковая что в mnist и в cifar10.\n",
        "Модель работала не так хорошо, как с mnist. Кроме того есть большой разрыв между точностью обучения и валидацией: модель превосходит данные обучения.\n",
        "\n",
        "Существует несколько методов, которые могут помочь уменьшить переобучение, таких как получение большего количества данных, отсев, увеличение объема данных, регуляризация."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxmG0YPK1Zwm"
      },
      "outputs": [],
      "source": [
        "\n",
        "import scipy.io as sio\n",
        "\n",
        "import numpy\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# normalize inpus from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_validation=X_test[0:100,:,:,:]\n",
        "X_test1=X_test[100:,:,:,:]\n",
        "\n",
        "y_validation=y_test[0:100]\n",
        "y_test1=y_test[100:]\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test1 = np_utils.to_categorical(y_test1)\n",
        "num_classes = y_test1.shape[1]\n",
        "y_validation = np_utils.to_categorical(y_validation)\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=( 32, 32,3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "epochs = 100\n",
        "lrate = 0.01\n",
        "decay = lrate/epochs\n",
        "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_validation, y_validation), epochs=epochs, batch_size=32)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test1, y_test1, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "model.save('model_cifar10_mydesign_new_way_nov12.h5')\n",
        "model.save_weights('model_weights_cifar10_mydesign_new_way_nov12.h5')\n",
        "\n",
        "y_test_arg=np.argmax(y_test1,axis=1);\n",
        "sio.savemat('y_test_cifar10_new_way_nov12.mat', {'y_test1': y_test1})\n",
        "sio.savemat('y_test_arg_cifar10_new_way_nov12.mat', {'y_test_arg': y_test_arg})\n",
        "y_pred=model.predict(X_test1,verbose=0)\n",
        "\n",
        "sio.savemat('y_pred_cifar10_new_way_nov12.mat', {'y_pred': y_pred})\n",
        "y_pred_arg=np.argmax(y_pred,axis=1);\n",
        "sio.savemat('y_pred_arg_cifar10_new_way_nov12.mat', {'y_pred_arg': y_pred_arg})\n",
        "\n",
        "from vis.visualization import visualize_activation\n",
        "from vis.utils import utils\n",
        "from keras import activations\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (18, 6)\n",
        "\n",
        "# Utility to search for layer index by name.\n",
        "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
        "layer_idx = utils.find_layer_idx(model, 'dense_3')\n",
        "\n",
        "# Swap softmax with linear\n",
        "model.layers[layer_idx].activation = activations.linear\n",
        "model = utils.apply_modifications(model)\n",
        "\n",
        "# This is the output node we want to maximize.\n",
        "filter_idx = 0\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "\n",
        "for tv_weight in [1e-3, 1e-2, 1e-1, 1, 10]:\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    img = visualize_activation(model, layer_idx, filter_indices=filter_idx, input_range=(0., 1.),\n",
        "                               tv_weight=tv_weight, lp_norm_weight=0.)\n",
        "    plt.figure()\n",
        "    plt.imshow(img[..., 0])\n",
        "\n",
        "\n",
        "\n",
        "for output_idx in np.arange(10):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    img = visualize_activation(model, layer_idx,tv_weight=10, filter_indices=output_idx, input_range=(0., 1.))\n",
        "    plt.figure()\n",
        "    plt.title('Networks perception of {}'.format(output_idx))\n",
        "    plt.imshow(img[..., 0])\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "for output_idx in np.arange(10):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    number=441+output_idx\n",
        "    img = visualize_activation(model, layer_idx,tv_weight=100, filter_indices=output_idx, input_range=(0., 1.))\n",
        "\n",
        "    plt.title('Networks perception of {}'.format(output_idx))\n",
        "    plt.subplot(number)\n",
        "\n",
        "    plt.imshow(img[..., 0])\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.5)\n",
        "for output_idx in np.arange(0,10):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    number=431+output_idx\n",
        "    img = visualize_activation(model, layer_idx,tv_weight=100, filter_indices=output_idx, input_range=(0., 1.))\n",
        "\n",
        "    plt.title('Networks perception of {}'.format(output_idx))\n",
        "    plt.subplot(number)\n",
        "\n",
        "    plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=1)\n",
        "for output_idx in np.arange(0, 10):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    number = 431 + output_idx\n",
        "    plt.subplot(number)\n",
        "    img = visualize_activation(model, layer_idx, tv_weight=100, filter_indices=output_idx, input_range=(0., 1.))\n",
        "    plt.title('Networks perception of {}'.format(output_idx))\n",
        "\n",
        "    plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# for layer 0\n",
        "#preprocessing conv2d_5\n",
        "\n",
        "\n",
        "layer_idx = utils.find_layer_idx(model, 'conv2d_1')\n",
        "\n",
        "# Swap softmax with linear\n",
        "model.layers[layer_idx].activation = activations.linear\n",
        "model = utils.apply_modifications(model)\n",
        "\n",
        "# This is the output node we want to maximize.\n",
        "filter_idx = 0\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx, input_range=(0., 1.))\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx, input_range=(0., 1.), verbose=True)\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx, input_range=(0., 1.),\n",
        "                           tv_weight=0., lp_norm_weight=0., verbose=True)\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "for tv_weight in [1e-3, 1e-2, 1e-1, 1, 10]:\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    img = visualize_activation(model, layer_idx, filter_indices=filter_idx, input_range=(0., 1.),\n",
        "                               tv_weight=tv_weight, lp_norm_weight=0.)\n",
        "    plt.figure()\n",
        "    plt.imshow(img[..., 0])\n",
        "\n",
        "#findal output\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=1)\n",
        "for output_idx in np.arange(0, 32):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    number = 661 + output_idx\n",
        "    plt.subplot(number)\n",
        "    img = visualize_activation(model, layer_idx, filter_indices=output_idx, input_range=(0., 1.))\n",
        "\n",
        "    # plt.title('Networks perception of {}'.format(output_idx+1))\n",
        "\n",
        "\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
