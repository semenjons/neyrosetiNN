{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOu0IoNlxm9l"
      },
      "source": [
        "## Урок 4. Сверточные нейронные сети\n",
        "- Попробуйте улучшить точность распознавания образов cifar 10 сверточной нейронной сетью, <br>рассмотренной на уроке. Приложите анализ с описанием того, что улучшает <br>работу нейронной сети, а что ухудшает\n",
        "- Опишите в анализе, какие изменения необходимо было бы внести в получившуюся нейронную сеть,<br> если бы ей нужно было работать не с cifar10, а с MNIST, CIFAR100 и IMAGENET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfFNC6O8xeMA"
      },
      "source": [
        "mnist - Мы получаем точность около 87,5% при проверке набора после 20 эпох, в то время как с полностью подключенной нейронной сетью мы получаем 85% <br>\n",
        "cifar10 - По истечении 20 эпох точность нашей проверки не превысила 73%, в то время как точность  обучения продолжает расти до 92%.\n",
        "\n",
        "cifar10 - этот набор данных более сложный, чем mnist\n",
        "сверточная нейронная сеть будет представлять собой набор измененных слоев <br>Conv2D и MaxPooling2D одинаковая что в mnist и в cifar10.\n",
        "Модель работала не так хорошо, как с mnist. Кроме того есть большой разрыв между точностью обучения и валидацией: модель превосходит данные обучения.\n",
        "\n",
        "Существует несколько методов, которые могут помочь уменьшить переобучение, таких как получение большего количества данных, отсев, увеличение объема данных, регуляризация.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "3_t-5oxAn9ZO",
        "outputId": "ee6dc933-2b29-4c89-fe48-a1b727bb5a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 100), dtype=tf.float32, name=None), name='dropout_1/Identity:0', description=\"created by layer 'dropout_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 3, 3, 100), dtype=tf.float32, name=None), name='dropout_2/Identity:0', description=\"created by layer 'dropout_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 100), dtype=tf.float32, name=None), name='dropout_3/Identity:0', description=\"created by layer 'dropout_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 100), dtype=tf.float32, name=None), name='dropout_3/Identity:0', description=\"created by layer 'dropout_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dense/Relu:0', description=\"created by layer 'dense'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_1/Softmax:0', description=\"created by layer 'dense_1'\")\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 198s 418ms/step - loss: 0.2286 - accuracy: 0.9283 - val_loss: 0.0479 - val_accuracy: 0.9863\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 183s 389ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.0342 - val_accuracy: 0.9899\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 181s 387ms/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 0.0321 - val_accuracy: 0.9913\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 181s 386ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0257 - val_accuracy: 0.9931\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 181s 386ms/step - loss: 0.0268 - accuracy: 0.9920 - val_loss: 0.0240 - val_accuracy: 0.9930\n",
            "Test loss: 0.023952385410666466\n",
            "Test accuracy: 0.9929999709129333\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3337278693cf>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m#visulization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize_activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vis'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 5\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "print(model.output)\n",
        "model.add(Conv2D(100, (5, 5), activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "print(model.output)\n",
        "model.add(Conv2D(100, (3, 3), activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "print(model.output)\n",
        "print(model.output)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "print(model.output)\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "print(model.output)\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "model.save('mnist_my_design_keras_vis_nov12.h5')\n",
        "#visulization\n",
        "\n",
        "from vis.visualization import visualize_activation\n",
        "from vis.utils import utils\n",
        "from keras import activations\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "#%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (18, 6)\n",
        "\n",
        "# Utility to search for layer index by name.\n",
        "# Alternatively we can specify this as -1 since it corresponds to the last layer.\n",
        "layer_idx = utils.find_layer_idx(model, 'dense_2')\n",
        "\n",
        "# Swap softmax with linear\n",
        "model.layers[layer_idx].activation = activations.linear\n",
        "model = utils.apply_modifications(model)\n",
        "\n",
        "# This is the output node we want to maximize.\n",
        "filter_idx = 0\n",
        "img = visualize_activation(model, layer_idx, filter_indices=filter_idx)\n",
        "plt.imshow(img[..., 0])\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=1)\n",
        "for output_idx in np.arange(0, 10):\n",
        "    # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "    number = 431 + output_idx\n",
        "    plt.subplot(number)\n",
        "    img = visualize_activation(model, layer_idx, tv_weight=10, filter_indices=output_idx, input_range=(0., 1.))\n",
        "    plt.title('Networks perception of {}'.format(output_idx))\n",
        "    plt.imshow(img[..., 0])\n",
        "plt.show()\n",
        "\n",
        "for layer_idx1 in range(0, 13):\n",
        "    fig = plt.figure()\n",
        "    # fig.subplots_adjust(hspace=1)\n",
        "    for output_idx in np.arange(0, 32):\n",
        "        # Lets turn off verbose output this time to avoid clutter and just see the output.\n",
        "        number = 430 + output_idx\n",
        "        ax = fig.add_subplot(6, 6, output_idx + 1)\n",
        "        img = visualize_activation(model, layer_idx=layer_idx1, filter_indices=output_idx, input_range=(0., 1.),\n",
        "                                   tv_weight=1e-1, lp_norm_weight=0.)\n",
        "        # plt.title('Networks perception of {}'.format(output_idx+1))\n",
        "        ax.imshow(img[..., 0])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.tight_layout()\n",
        "    plt.show()\n",
        "    fig.savefig(\"mnist_layer_number_\" + str(layer_idx1) + '_new_design.jpg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
